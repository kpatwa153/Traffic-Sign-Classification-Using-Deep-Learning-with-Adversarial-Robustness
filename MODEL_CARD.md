# Model Card
There are two classification model for classifying the traffic sign image. Process for both the model is same.
1. The model is trained on the training set and then the accuracy is checked against the test data.
2. Using Effective adversarial attacking methods and techniques, the test images were perturbed, transformed and distorted. Model was then ran against this new test data and the accuracy was measured.
3. Finally, the model was trained on defensive techniques like eliminating noise, Various transformations like Gaussian Blur, Jitters, Random Cropping, flips, Fast Gradient method or projected gradient descent to tackle the adversarial attack. 
4. Accuracy of this newly trained model was checked against the new test data.


## Kenil's Model:
### Classification Model:
1. The Classification created has Two Convolutional Layers, each followed by ReLU activation and max pooling to extract spatial features. 
2. Followed by these two convolutional layer is the Fully connected layer to reduce feature maps into class probabilities.
3. The final layer outputs the prediction for the traffic sign image.
4. Adam Optimizer and Cross Entropy Loss function is used as loss function, suitable for multi-class classification task.

### Adversarial Attacking Technique:
The attack is based upon the Generative Adversarial Network (GAN) with adversarial techniques for generating and refining adversarial examples.
1. Generator is used to create images and then Gaussian noise and distortion is applied to it to stimulate natural image variability.
2. Discriminator evaluates the authenticity of images generated. It is trained to distinguish between the images from the dataset and adversarial perturbed fake images.
3. Fast Gradient Sign Method (FGSM) is used to perturb the images from the generator to make it difficult for the Discriminator to classify the image as fake.

The GAN model is trained on the train dataset with both Generator and Discriminator using Binary Cross Entropy loss as their loss function.

### Defensive Technique:
To Tackle the Adversarial attack, a defensive technique was put in place
1. Defensive transformations like Random rotation, Distortion, Gaussian blur were applied to improve robutness
2. While training the classification model on these transformations, adversarial examples generated by PGD attack was used along with clean images.
3. The Classification model was trained on both clean and adversarial images to make it more robust and maintain the accuracy of it.


## Naman's Model:
### Classification Model:
1. The model is made up of two convolutional layer each followed by ReLU activation and Max Pooling for dimensionality Reduction
2. Fully Connected layer then flattens the feature maps and it is passed through two dense layer with the latter outputting class probabilities.
3. Adam optimizer is used for weight updates and Cross Entropy Loss function for classification

### Adversarial Attacking Technique:
1. The technique uses PGD with preprocessing transformations. It first applies transformations like color jitters, additive noise to the image.
2. Image is then perturbed by finding the gradient of the loss with respect to the input and then adding additional noise to it.

### Defensive Technique:
To improve the model's robutness against the attack,
1. Model is trained on PGD generated images for each epoch.
2. Adversarial generated images are combined with the clean data and the model is trained on this combined dataset to maintain the accuracy and robutness.